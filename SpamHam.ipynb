{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pCwoWRJq6NpI"},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","import nltk\n","# nltk.download('stopwords')\n","# nltk.download('punkt')\n","# nltk.download('wordnet')\n","# nltk.download('averaged_perceptron_tagger')\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sd8mcW86NpK","outputId":"595a2b9e-3e1c-417a-a9ab-8fe19616d1c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["wait\n","wait\n","wait\n","wait\n"]}],"source":["from nltk.stem import PorterStemmer\n","e_words= [\"wait\", \"waiting\", \"waited\", \"waits\"]\n","ps =PorterStemmer()\n","for w in e_words:\n","    rootWord=ps.stem(w)\n","    print(rootWord)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sx-3u2rm6NpL","outputId":"851c674c-975a-4daf-de95-9c6aadeaa57d"},"outputs":[{"name":"stdout","output_type":"stream","text":["hello\n","guru99\n",",\n","you\n","have\n","to\n","build\n","a\n","veri\n","good\n","site\n","and\n","I\n","love\n","visit\n","your\n","site\n",".\n"]}],"source":["from nltk.stem import PorterStemmer\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","sentence=\"Hello Guru99, You have to build a very good site and I love visiting your site.\"\n","words = word_tokenize(sentence)\n","ps = PorterStemmer()\n","for w in words:\n","    rootWord=ps.stem(w)\n","    print(rootWord)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWAStyJ16NpL","outputId":"373dfdda-f275-4d5e-d4a8-69680edc3740"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stemming for studies is studi\n","Stemming for studying is studi\n","Stemming for cries is cri\n","Stemming for cry is cri\n"]}],"source":["import nltk\n","from nltk.stem.porter import PorterStemmer\n","porter_stemmer  = PorterStemmer()\n","text = \"studies studying cries cry\"\n","tokenization = nltk.word_tokenize(text)\n","for w in tokenization:\n","    print(\"Stemming for {} is {}\".format(w,porter_stemmer.stem(w)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZ8zSzzS6NpL","outputId":"7b0b0320-ea18-4ec8-b1dc-33cc0b76d77f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Lemma for studies is study\n","Lemma for studying is studying\n","Lemma for cries is cry\n","Lemma for cry is cry\n"]}],"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","text = \"studies studying cries cry\"\n","tokenization = nltk.word_tokenize(text)\n","for w in tokenization:\n","    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WR7AqouO6NpL","outputId":"b0dbfd3d-1842-4d75-b6ea-6d5a3c66518b"},"outputs":[{"name":"stdout","output_type":"stream","text":["guru99 => guru99\n","is => be\n","a => a\n","totally => totally\n","new => new\n","kind => kind\n","of => of\n","learning => learn\n","experience => experience\n",". => .\n"]}],"source":["from nltk.corpus import wordnet as wn\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk import word_tokenize, pos_tag\n","from collections import defaultdict\n","tag_map = defaultdict(lambda : wn.NOUN)\n","tag_map['J'] = wn.ADJ\n","tag_map['V'] = wn.VERB\n","tag_map['R'] = wn.ADV\n","\n","text = \"guru99 is a totally new kind of learning experience.\"\n","tokens = word_tokenize(text)\n","lemma_function = WordNetLemmatizer()\n","for token, tag in pos_tag(tokens):\n","    lemma = lemma_function.lemmatize(token, tag_map[tag[0]])\n","    print(token, \"=>\", lemma)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9p-Mlttt6NpM"},"outputs":[],"source":["data = pd.read_csv('spam.csv', encoding = 'latin-1')\n","data = data[['v1', 'v2']]\n","data = data.rename(columns = {'v1': 'label', 'v2': 'text'})\n","data['text'] = data['text'].str.lower()\n","\n","# stopwords, stemming and lemmatization\n","# stopwords = set(stopwords.words('english'))\n","# data['text'] = data['text'].apply(lambda msg: ' '.join([word for word in msg.split() if word not in stopwords]))\n","\n","# Stemming vs Lemmatization (saved)\n","# lemmatizer = WordNetLemmatizer()\n","# print(data['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etlMl-IA6NpM","outputId":"4d5a028c-b79c-4f10-d8ce-b48dd732ced6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9641255605381166\n","[[960   0]\n"," [ 40 115]]\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size = 0.2)\n","\n","vectorizer = TfidfVectorizer()\n","X_train = vectorizer.fit_transform(X_train)\n","\n","clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n","\n","X_test = vectorizer.transform(X_test)\n","y_pred = clf.predict(X_test)\n","print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n","print(confusion_matrix(y_test, y_pred))\n","\n","def pred(msg):\n","    msg = vectorizer.transform([msg])\n","    prediction = clf.predict(msg)\n","    return prediction[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJUopnCB6NpM","outputId":"96f16430-7bb5-4601-e31e-d38a474e31cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["ham\n"]}],"source":["print(pred('Hello, I want to congratulate you on all you have done.'))\n","print(pred('Congratulations! You have won $1000000. Click here to claim your prize.'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RX-7UJpT6NpM","outputId":"88d32d65-da9f-48c3-9dfb-285ce2dabbdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["spam\n"]}],"source":["print(pred('Congratulations! You have won $1000000. Click here to claim your prize.'))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}