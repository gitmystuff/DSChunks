{"cells":[{"cell_type":"markdown","id":"14d5dfc8","metadata":{"id":"14d5dfc8"},"source":["# Multinomial Logistic Regression"]},{"cell_type":"code","execution_count":null,"id":"691a5153","metadata":{"scrolled":false,"id":"691a5153","outputId":"0cc68c2d-39a2-40da-b31d-e6f149e3a0d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]]\n","\n","[[6 2 1]\n"," [2 7 0]\n"," [0 0 7]]\n","\n","Predicted  0  1  2  All\n","Actual                 \n","0          6  2  1    9\n","1          2  7  0    9\n","2          0  0  7    7\n","All        8  9  8   25\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.67      0.71         9\n","           1       0.78      0.78      0.78         9\n","           2       0.88      1.00      0.93         7\n","\n","    accuracy                           0.80        25\n","   macro avg       0.80      0.81      0.81        25\n","weighted avg       0.80      0.80      0.80        25\n","\n"]}],"source":["# multi-label confusion matrix\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, classification_report\n","\n","\n","# create data\n","features, multi_class = make_classification(n_samples=100, n_features=4,\n","                                             n_informative=4, n_redundant=0,\n","                                             n_classes=3, random_state=13)\n","# create a dataframe of the features and add the binary class (label, output)\n","df = pd.DataFrame(features)\n","df.columns = ['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4']\n","df['Class'] = multi_class\n","\n","# train test split\n","X_train, X_test, y_train, y_test = train_test_split(df.drop(['Class'], axis=1), df['Class'], test_size=0.25, random_state=42)\n","X_train.head()\n","\n","# create model\n","model = LogisticRegression(solver='liblinear', random_state=42)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","# create matrix number map\n","print(np.array(range(1, 10)).reshape(3, 3))\n","print()\n","print(confusion_matrix(y_test, y_pred))\n","print()\n","print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True))\n","print()\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"id":"2222d71d","metadata":{"id":"2222d71d","outputId":"2f605087-6ab4-479f-e7c6-522c055f1a37"},"outputs":[{"data":{"text/plain":["array([[[14,  2],\n","        [ 3,  6]],\n","\n","       [[14,  2],\n","        [ 2,  7]],\n","\n","       [[17,  1],\n","        [ 0,  7]]], dtype=int64)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/\n","multilabel_confusion_matrix(y_test, y_pred)"]},{"cell_type":"markdown","id":"224c5a41","metadata":{"id":"224c5a41"},"source":["### Class 0"]},{"cell_type":"code","execution_count":null,"id":"f4f9f94d","metadata":{"id":"f4f9f94d","outputId":"ba417a83-4eb6-4b10-f4fb-306b486bf4b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]]\n","\n","[[6 2 1]\n"," [2 7 0]\n"," [0 0 7]]\n","\n","[[14  2]\n"," [ 3  6]]\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.67      0.71         9\n","           1       0.78      0.78      0.78         9\n","           2       0.88      1.00      0.93         7\n","\n","    accuracy                           0.80        25\n","   macro avg       0.80      0.81      0.81        25\n","weighted avg       0.80      0.80      0.80        25\n","\n"]}],"source":["print(np.array(range(1, 10)).reshape(3, 3))\n","print()\n","print(confusion_matrix(y_test, y_pred))\n","print()\n","print(multilabel_confusion_matrix(y_test, y_pred)[0])\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","id":"93fac7e4","metadata":{"id":"93fac7e4"},"source":["Class 0\n","* TN = add cells 5, 6, 8, 9\n","* FP = add cells 4, 7\n","* FN = add cells 2, 3\n","* TP = cell 1"]},{"cell_type":"markdown","id":"dcd95a1f","metadata":{"id":"dcd95a1f"},"source":["### Class 1"]},{"cell_type":"code","execution_count":null,"id":"75f74ece","metadata":{"id":"75f74ece","outputId":"11f0803d-fa91-47cb-a888-37c094763758"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]]\n","\n","[[6 2 1]\n"," [2 7 0]\n"," [0 0 7]]\n","\n","[[14  2]\n"," [ 2  7]]\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.67      0.71         9\n","           1       0.78      0.78      0.78         9\n","           2       0.88      1.00      0.93         7\n","\n","    accuracy                           0.80        25\n","   macro avg       0.80      0.81      0.81        25\n","weighted avg       0.80      0.80      0.80        25\n","\n"]}],"source":["print(np.array(range(1, 10)).reshape(3, 3))\n","print()\n","print(confusion_matrix(y_test, y_pred))\n","print()\n","print(multilabel_confusion_matrix(y_test, y_pred)[1])\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","id":"b9feeab1","metadata":{"id":"b9feeab1"},"source":["Class 1\n","* TN = add the corners cells 1, 3, 7, 9\n","* FP = add cells 2, 8\n","* FN = add cells 4, 6\n","* TP = cell 5"]},{"cell_type":"markdown","id":"5b60f3e1","metadata":{"id":"5b60f3e1"},"source":["### Class 2"]},{"cell_type":"code","execution_count":null,"id":"8f679814","metadata":{"id":"8f679814","outputId":"390bb4e8-d959-4b77-d3a9-f0665d8c8d48"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]]\n","\n","[[6 2 1]\n"," [2 7 0]\n"," [0 0 7]]\n","\n","[[17  1]\n"," [ 0  7]]\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.67      0.71         9\n","           1       0.78      0.78      0.78         9\n","           2       0.88      1.00      0.93         7\n","\n","    accuracy                           0.80        25\n","   macro avg       0.80      0.81      0.81        25\n","weighted avg       0.80      0.80      0.80        25\n","\n"]}],"source":["print(np.array(range(1, 10)).reshape(3, 3))\n","print()\n","print(confusion_matrix(y_test, y_pred))\n","print()\n","print(multilabel_confusion_matrix(y_test, y_pred)[2])\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","id":"d931aada","metadata":{"id":"d931aada"},"source":["Class 2\n","* TN = add the corners cells 1, 2, 4, 5\n","* FP = add cells 3, 6\n","* FN = add cells 7, 8\n","* TP = cell 9"]},{"cell_type":"markdown","id":"65a4ea9c","metadata":{"id":"65a4ea9c"},"source":["### Test Statistics\n","\n","\n","\n","The $2 \\times 2$ confusion matrix (assuming '1' is the **Positive** class and '0' is the **Negative** class) is defined by the following four counts:\n","\n","| Outcome | Definition | Status |\n","| :--- | :--- | :--- |\n","| **True Negative (TN)** | $\\text{Predicted } 0 \\text{, Actual } 0$ | **Correctly** identified the negative class. |\n","| **False Positive (FP)** | $\\text{Predicted } 1 \\text{, Actual } 0$ | **Incorrectly** identified the positive class (Type I Error). |\n","| **False Negative (FN)** | $\\text{Predicted } 0 \\text{, Actual } 1$ | **Incorrectly** identified the negative class (Type II Error). |\n","| **True Positive (TP)** | $\\text{Predicted } 1 \\text{, Actual } 1$ | **Correctly** identified the positive class. |\n","\n","***\n","\n","## Clarification of Misleading Summation Points\n","\n","The concepts of summing rows and columns are generally used to calculate the **marginal totals** (the row/column sums) or to derive metrics in a **multi-class** (more than $2$ classes) scenario, not to define the individual cells of a $2 \\times 2$ matrix.\n","\n","| User's Statement | Verification and Correction |\n","| :--- | :--- |\n","| **TN** = cases except for the values of the class... | **Incorrect.** In a $2 \\times 2$ matrix, $\\text{TN}$ is simply the count in the (Actual 0, Predicted 0) cell. The definition sounds like a confusing attempt to describe the overall **Grand Total** minus the positive class totals. |\n","| **FP** = sum of values of the columns except $\\text{TP}$ | **Incorrect.** The sum of the column except $\\text{TP}$ is simply **FN** (if looking at the Actual Positive column) or is not a meaningful standard metric. $\\text{FP}$ is the count in the (Actual 0, Predicted 1) cell. |\n","| **FN** = sum of values of the row except for $\\text{TP}$ | **Incorrect.** The sum of the row except $\\text{TP}$ is simply **FP** (if looking at the Predicted Positive row) or is not a meaningful standard metric. $\\text{FN}$ is the count in the (Actual 1, Predicted 0) cell. |\n","| **TP** = case where the predicted values match the actual values | **Incomplete.** This also describes $\\text{TN}$. $\\text{TP}$ is specifically the case where **both** the predicted and actual values match the **Positive (1) class**. |\n","\n","https://www.projectpro.io/recipes/explain-multiclass-confusion-matrix"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}