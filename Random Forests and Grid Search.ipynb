{"cells":[{"cell_type":"markdown","id":"22b12e34","metadata":{"id":"22b12e34"},"source":["# Random Forests and Grid Search\n","\n","## Random Forests\n","\n","Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n","\n","https://en.wikipedia.org/wiki/Random_forest\n","\n","* Trees are notorious for overfitting\n","* IID vs ID (Identically distributed but not Independent)\n","* Random Forest tries to reduce this correlation by building trees decorrelated from each other using depth, width, leaf node, etc. bagging\n","* More nodes means less bias but more variance\n","* Ensemble trees can have some with high bias and some with low bias\n","* Ensemble provides different perspectives of y while neural net uses dropout where weights remain the same, just not used\n","\n","## Cross Validation\n","\n","Cross-validation, sometimes called rotation estimation or out-of-sample testing, is any of various similar model validation techniques for assessing how the results of a statistical analysis will generalize to an independent data set. Cross-validation is a resampling method that uses different portions of the data to test and train a model on different iterations.\n","\n","https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n","\n","## Hyperparameter\n","\n","In machine learning, a hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are derived via training. Hyperparameters can be classified as model hyperparameters, that cannot be inferred while fitting the machine to the training set because they refer to the model selection task, or algorithm hyperparameters, that in principle have no influence on the performance of the model but affect the speed and quality of the learning process.\n","\n","https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)\n","\n","## Grid Search\n","\n","The traditional way of performing hyperparameter optimization has been grid search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a hold-out validation set.\n","\n","https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search"]},{"cell_type":"code","execution_count":null,"id":"e32f8439","metadata":{"id":"e32f8439","outputId":"f5aff74d-3157-4b47-c34a-2da2ba91685e"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 344 entries, 0 to 343\n","Data columns (total 7 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   species            344 non-null    object \n"," 1   island             344 non-null    object \n"," 2   bill_length_mm     342 non-null    float64\n"," 3   bill_depth_mm      342 non-null    float64\n"," 4   flipper_length_mm  342 non-null    float64\n"," 5   body_mass_g        342 non-null    float64\n"," 6   sex                333 non-null    object \n","dtypes: float64(4), object(3)\n","memory usage: 18.9+ KB\n","None\n"]}],"source":["# use the penguins dataset; species = y; explore the dataset\n","import pandas as pd\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import OneHotEncoder\n","\n","df = sns.load_dataset('penguins')\n","print(df.info())\n","df.dropna(how='any', inplace=True)\n","X_train, X_test, y_train, y_test = train_test_split(df.drop('species', axis=1), df['species'], test_size=0.25, random_state=42)\n","\n","X_train['sex'] = X_train['sex'].map({'Female':1,'Male':0})\n","X_test['sex'] = X_test['sex'].map({'Female':1,'Male':0})\n","\n","ohe = OneHotEncoder(categories='auto', drop='first', sparse=False)\n","\n","ohe_train = ohe.fit_transform(X_train[['island']])\n","ohe_train = pd.DataFrame(ohe_train, columns=ohe.get_feature_names_out(['island']))\n","ohe_train.index = X_train.index\n","X_train = X_train.join(ohe_train)\n","X_train.drop(['island'], axis=1, inplace=True)\n","\n","ohe_test = ohe.transform(X_test[['island']])\n","ohe_test = pd.DataFrame(ohe_test, columns=ohe.get_feature_names_out(['island']))\n","ohe_test.index = X_test.index\n","X_test = X_test.join(ohe_test)\n","X_test.drop(['island'], axis=1, inplace=True)\n","\n","y_train.value_counts()\n","y_train = y_train.map({'Adelie':0,'Gentoo':1, 'Chinstrap':2})\n","y_test = y_test.map({'Adelie':0,'Gentoo':1, 'Chinstrap':2})"]},{"cell_type":"code","execution_count":null,"id":"2c2d294b","metadata":{"id":"2c2d294b","outputId":"fcfd0707-6f4f-4c29-8147-8d4bb1e4b6cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["best accuracy 0.992\n","best parameters {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 4, 'max_leaf_nodes': 9, 'n_estimators': 200}\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","hyperparameters = {\n","            'n_estimators': [50, 200],\n","            'criterion': ['entropy', 'gini'],\n","            'max_depth': [3, 4],\n","            'max_leaf_nodes': [7, 9],\n","            'bootstrap': [True, False]\n","            }\n","\n","grid_search = GridSearchCV(estimator = RandomForestClassifier(),\n","                           param_grid = hyperparameters,\n","                           scoring = 'accuracy',\n","                           cv = 10)\n","\n","grid_search = grid_search.fit(X_train, y_train)\n","\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_\n","\n","print('best accuracy', best_accuracy)\n","print('best parameters', best_parameters)"]},{"cell_type":"markdown","id":"d85f8f10","metadata":{"id":"d85f8f10"},"source":["## Our Final Model with Best (Hyper)Parameters\n","\n","best_params from gridsearch: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_leaf_nodes': 7, 'n_estimators': 50}\n","\n","<pre>\n","model = RandomForestClassifier(\n","            n_estimators=50,\n","            criterion='entropy',\n","            max_depth=3,\n","            max_leaf_nodes=7,\n","            bootstrap=True\n","            )\n","</pre>"]},{"cell_type":"code","execution_count":null,"id":"714fc5a2","metadata":{"id":"714fc5a2","outputId":"244904b4-8116-4da5-fc5d-6528243b4b20"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9880952380952381\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","model = RandomForestClassifier(n_estimators = 50,\n","                               criterion = 'entropy',\n","                               max_depth = 3,\n","                               max_leaf_nodes = 7,\n","                               bootstrap = True,\n","                               random_state = 42)\n","\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)\n","print(accuracy_score(y_test, predictions))"]},{"cell_type":"code","execution_count":null,"id":"f98028e0","metadata":{"id":"f98028e0","outputId":"649b364e-9bce-498c-a504-05b20a88a465"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9880952380952381\n","<bound method BaseEstimator.get_params of RandomForestClassifier(criterion='entropy', max_depth=4, max_leaf_nodes=9,\n","                       n_estimators=200, random_state=42)>\n"]}],"source":["# build your final RandomForestClassifier model here using set_params and best_params; provide an accuracy score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","model = RandomForestClassifier(random_state = 42).set_params(**best_parameters) # * args, ** kwargs\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)\n","print(accuracy_score(y_test, predictions))\n","print(model.get_params)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}