{"cells":[{"cell_type":"markdown","id":"a53d4ead","metadata":{"id":"a53d4ead"},"source":["# Imputation\n","**Created by:** Jenny Liang (zhenni.liang@unt.edu)\n","\n","**What is Imputation?**\n","---\n","*Definition*\n","*   \"Replacing missing or invalid data with substitute values.\"\n","*   **Imputation** in statistics is the process of replacing missing data with substituted values. These substituted values are calculated as statistically plausible estimates using the observed values present in the dataset. When a full data point is substituted, it is called \"unit imputation,\" and when a component of a data point is substituted, it is called \"item imputation\"\n","*   **Imputation** is a crucial step in data preprocessing because missing values are a common feature of real-world datasets and pose a challenge to data scientists. If data gaps are not managed properly, they can introduce substantial bias, reduce statistical power, and lead to poor performance when applying most machine learning algorithms.\n","---\n","*Why missingness matters*\n","*   The primary motivation for using imputation is to preserve the integrity and completeness of the dataset.\n","*   Avoiding Data Loss and Bias and Capturing Data Properties\n","---\n","*When imputation is necessary vs. when deletion is acceptable*\n","\n","Deletion is generally acceptable or utilized when:\n","*   Missingness is minimal and random.\n","*   Missing Completely At Random (MCAR) [more on this soon]\n","*   Simplicity and Ease of Use are Paramount.\n","\n","Imputation is necessary when:\n","*   Missingness is Substantial.\n","*   Missingness is Not Completely Random (MAR or NMAR) [more on this soon]\n","*   Preserving Statistical Power and Data Integrity.\n","*   Applying Machine Learning Models: Missing values pose a challenge because most machine learning algorithms perform poorly in the presence of incomplete data. Imputation is typically a required preprocessing step for these models.\n"]},{"cell_type":"markdown","source":["**Types of Missing Data**\n","\n","*MCAR — Missing Completely At Random*\n","*   The missingness has nothing to do with the data.\n","*   In this scenario, the probability of missing data depends only on the overall probability of data being missing. This pattern is easiest to handle because ignoring MCAR data does not bias the results.\n","*   Example: A sensor randomly fails 5% of the time.\n","\n","*MAR — Missing At Random*\n","*   Missingness related to observed variables.\n","*   The probability of data being missing depends on both the overall probability of missing data and the observed data. Analysts can impute values for MAR data with reasonable confidence because the pattern of missingness is explainable by the variables already observed.\n","*   Example: Income missing more often for younger respondents.\n","\n","*MNAR — Missing Not At Random*\n","*   Missingness depends on the unobserved value itself.\n","*    The value of the unobserved responses depends on information not available for analysis, making future observations impossible to predict without bias using only the model's observed data. MNAR data is generally the most challenging type to handle.\n","*   Example: High incomes are more likely to be withheld because they are high.\n","\n","*Why this matters:*\n","*   Certain imputation methods only work well under MCAR/MAR.\n","*   Why? Imputation assumes you can predict missing values based on observed values. This is only true for MCAR and MAR. MNAR, by definition, hides values that differ from the observed ones making prediction unreliable.\n","\n"],"metadata":{"id":"KqA1AeXKuAbS"},"id":"KqA1AeXKuAbS"},{"cell_type":"markdown","source":["**Identifying Missing Data**\n","\n","*Common checks*\n","*    df.isnull().sum()\n","*    Percentage of missingness\n","*    Heatmap of missing patterns (sns.heatmap(df.isnull()))\n","*    Missingness by variable, row, type\n","\n","*Patterns to look for:*\n","*    Entire rows missing?\n","*    Entire columns partially missing?\n","*    Are missing values clustered?"],"metadata":{"id":"Gm9sOe-0ubw0"},"id":"Gm9sOe-0ubw0"},{"cell_type":"markdown","source":["**Common Imputation Strategies (Baseline)**\n","\n","*Deletion Methods*\n","*   Listwise deletion (drop rows): df.dropna()\n","*   When it’s acceptable: MCAR + small proportion missing.\n","*   Risks: removes information, creates bias if data is MAR or MNAR.\n","\n","*Simple Imputation*\n","*   Mean imputation (numerical)\n","```\n","df['col'].fillna(df['col'].mean())\n","```\n","*   Median imputation (good for skewed data)\n","*   Mode imputation (categorical)\n","```\n","df['col'].fillna(df['col'].mode()[0])\n","```\n","*   Constant imputation (useful for categorical missingness interpretation;\n","Example: `fillna(\"Unknown\")`\n"],"metadata":{"id":"IxMjzIN4uqlZ"},"id":"IxMjzIN4uqlZ"},{"cell_type":"markdown","source":["**Intermediate Imputation Techniques**\n","\n","*K-Nearest Neighbors (KNN) Imputation*\n","*   Idea: Finds similar records and uses neighbors’ values.\n","*   Pros: preserves structure, handles nonlinearities.\n","*   Cons: slow for large datasets, sensitive to scaling.\n","```\n","from sklearn.impute import KNNImputer\n","imputer = KNNImputer(n_neighbors=5)\n","X = imputer.fit_transform(df)\n","```\n","*Multivariate Imputation by Chained Equations (MICE)*\n","*  Idea: Models each feature with missing values as a function of others.\n","*  Iteratively imputes.\n","*  Good for MAR situations.\n","```\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","\n","imputer = IterativeImputer()\n","X = imputer.fit_transform(df)\n","```\n","*Regression Imputation*\n","* Idea: Build a regression model to estimate missing values.\n","* Example: predict missing heights using weight + age."],"metadata":{"id":"7U6Nubx_u1d6"},"id":"7U6Nubx_u1d6"},{"cell_type":"markdown","source":["**Advanced / Modern Imputation Techniques**\n","\n","*Random Forest Imputation*\n","* Models missing values using RF regressors/classifiers.\n","* Available through IterativeImputer with RF.\n","\n","*Autoencoder Imputation*\n","* Train an autoencoder neural network to reconstruct missing values.\n","\n","*Multiple Imputation*\n","* Creates multiple completed datasets and pools results.\n","* Offers better uncertainty quantification.\n","* Needed for serious statistical modeling."],"metadata":{"id":"m_kGEGr7vCCp"},"id":"m_kGEGr7vCCp"},{"cell_type":"markdown","source":["**Categorical vs Numeric Imputation**\n","\n","*Categorical*\n","* Examples: Mean, median, interpolation, regression, KNN, MICE\n","\n","*Numeric*\n","* Examples: Mode, constant category (“Missing”, “None”), predictive models (classification)"],"metadata":{"id":"U0y4WKWIvTfR"},"id":"U0y4WKWIvTfR"},{"cell_type":"markdown","source":["**Imputation in Train/Test Splits (VERY IMPORTANT)**\n","\n","Students often make this mistake.\n","```\n","# INCORRECT\n","imputer.fit_transform(full_dataset)  # leakage\n","```\n","*  **Never fit imputation on the full dataset.**\n","* Only fit on training data to avoid data leakage.\n","```\n","# CORRECT\n","imputer.fit(train_X)\n","train_X = imputer.transform(train_X)\n","test_X = imputer.transform(test_X)\n","```"],"metadata":{"id":"gnDSiZwtvjZK"},"id":"gnDSiZwtvjZK"},{"cell_type":"markdown","source":["**Evaluating Imputation Quality**\n","\n","*Compare distributions*\n","* Example: Before vs after imputation using histograms or summary stats.\n","\n","*Train a model*\n","* Test accuracy improvements vs deletion.\n","* Compare methods (mean vs KNN vs MICE).\n","\n","*Sensitivity analysis*\n","* Check how model outputs change when imputation methods vary."],"metadata":{"id":"AkNk2eEWv-Sr"},"id":"AkNk2eEWv-Sr"},{"cell_type":"markdown","source":["**Common Mistakes Students Make**\n","\n","*   Treating missing values as zeros without understanding implications.\n","*   Fitting imputation before splitting data.\n","*   Using mean imputation on skewed distributions.\n","*   Ignoring that different columns need different strategies.\n","*   Forgetting that categorical vs numerical require different approaches.\n","*   Blindly applying KNN without scaling.\n","*   Not evaluating the effect of imputation on model performance."],"metadata":{"id":"lEFp3HqXwvwp"},"id":"lEFp3HqXwvwp"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}